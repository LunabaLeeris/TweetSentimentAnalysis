{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing the dataset\n",
    "In order to save computation, the dataset was trimmed and only 4 classifications were chosen (sadness, joy, anger, fear) Which means there exist a total of 6 pair, hence 6 instances of SMO\n",
    "\n",
    "In order to properly perform one vs one SMO, each data per classification was splitted into different files. \n",
    "Each file have an ideal length of 5000 (taget_len). This means that each pair will have a collective length of 10,000. This length is carefully chosen because SMO, with gaussian kernels have a time compelxity of approximately $N^{2.9}$ and after testing, 10,000 training data will need 10 minutes to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully parsed data\n",
      "total train_count for training dataset: [5000    0 5000 5000 5000]\n",
      "total test_count for test dataset: [5000    0 5000 5000 5000]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "emotions: list = [\"sadness\", \"love\", \"joy\", \"anger\", \"fear\", \"surprise\"]\n",
    "csv_file_path: str = 'dataset/text.csv'\n",
    "test_file_path: str = 'test/'\n",
    "train_file_path: str = 'train/'\n",
    "train_count: np.int32 = np.zeros(shape=(len(emotions) - 1), dtype=np.int32)\n",
    "test_count: np.int32 = np.zeros(shape=(len(emotions) - 1), dtype=np.int32)\n",
    "total_len: int = 0\n",
    "\n",
    "target_len: int = 5000\n",
    "chunk_size: int = 1000\n",
    "\n",
    "csv_iterator: any = pd.read_csv(csv_file_path, chunksize=chunk_size)\n",
    "\n",
    "for chunk in csv_iterator:\n",
    "    for index, row in chunk.iterrows():\n",
    "        label: int = int(row[\"label\"])\n",
    "\n",
    "        # remove those with labels love and surprise\n",
    "        if (label == 1 or label == 5): \n",
    "            continue\n",
    "\n",
    "        if (train_count[label] < target_len):\n",
    "            with open(train_file_path + emotions[label] + \".txt\", 'a') as file:\n",
    "                file.write(row[\"text\"] + \"\\n\")\n",
    "\n",
    "            train_count[label] += 1\n",
    "            total_len += 1\n",
    "\n",
    "        elif (test_count[label] < target_len):\n",
    "            with open(test_file_path + emotions[label] + \".txt\", 'a') as file:\n",
    "                file.write(row[\"text\"] + \"\\n\")\n",
    "\n",
    "            test_count[label] += 1\n",
    "            total_len += 1\n",
    "\n",
    "        if total_len == target_len * 16:\n",
    "            break\n",
    "\n",
    "\n",
    "print(\"Succesfully parsed data\")\n",
    "print(\"total train_count for training dataset: \" + str(train_count))\n",
    "print(\"total test_count for test dataset: \" + str(test_count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
